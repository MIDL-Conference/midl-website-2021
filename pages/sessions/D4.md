---
title: "Session D4"
page_class: "program"
sidebar: false
---

{% from "_macros.html" import paper, cloudflare_video %}


# D4 - Detection and Diagnosis 1
##  Wednesday 7th July, 16:45 - 17:30 (UCT+2)
### Chairs: Tal Arbel, Hans Meine



---
                        
[% .papers %]
{{ paper('An AI-based Framework for Diagnostic Quality Assessment of Ankle Radiographs',
        'Dominik Mairhöfer, Manuel Laufer, Paul Martin Simon, Malte Sieren, Arpad Bischof, Thomas Käster, Erhardt Barth, Jörg Barkhausen, Thomas Martinetz',
        openreview='https://openreview.net/forum?id=bj04hJss_xZ',
        pdf='/proceedings/mairhoefer21.pdf',
        id='D10',
        paper='papers/D10.html',
        proceedings='',
        abstract='The quality of radiographs is of major importance for diagnosis and treatment planning. While most research regarding automated radiograph quality assessment uses technical features such as noise or contrast, we propose to use anatomical structures as more appropriate features. We show that based on such anatomical features, a modular deep-learning framework can serve as a quality control mechanism for the diagnostic quality of ankle radiographs. For evaluation, a dataset consisting of 950 ankle radiographs was collected and their quality was labeled by radiologists. We obtain an average accuracy of 94.1%, which is better than the expert radiologists are on average.')
}}
[% / %]
                        
{{ cloudflare_video('9634a968ce994c5ca0a1d02a327e04e2') }}
                        

---
                        
[% .papers %]
{{ paper('Image Sequence Generation and Analysis via GRU and Attention for Trachomatous Trichiasis Classification',
        'Juan Carlos Prieto, Hina Shah, Kasey Jones, Robert F Chew, Hashiya M. Kana, Jerusha Weaver, Rebecca M. Flueckiger, Scott McPherson, Emily W. Gower',
        openreview='https://openreview.net/forum?id=umb5xsy1-zS',
        pdf='/proceedings/prieto21.pdf',
        id='D11',
        paper='papers/D11.html',
        proceedings='',
        abstract='Chlamydia trachomatous is an infectious ocular condition that can cause the eyelid to turn inward so that one or more eyelashes touch the eyeball, a condition call trachomatous trichiasis (TT), which can lead to blindness. Community-based screeners are used in rural areas to identify patients with TT, who can then be referred for proper medical care. Having automatic methods to detect TT will reduce the amount of time required to train screeners and improve accuracy of detection. This paper proposes a method to automatically identify regions of an eye and identify TT, using photographs taken with smartphones in the field. The attention-based gated deep learning networks in combination with a regionidentification network can identify TT with an accuracy of 91%, sensitivity of 92% and specificity of 87%, showing that these methods have the potential to be deployed in the field.')
}}
[% / %]
                        
{{ cloudflare_video('abbe5f8ef7790d4e339374be2a2b86d1') }}
                        

---
                        
[% .papers %]
{{ paper('MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models',
        'Hari Sowrirajan, Jingbo Yang, Andrew Y. Ng, Pranav Rajpurkar',
        openreview='https://openreview.net/forum?id=LO7Su0-dPJl',
        pdf='/proceedings/sowrirajan21.pdf',
        id='D12',
        paper='papers/D12.html',
        proceedings='',
        abstract='Contrastive learning is a form of self-supervision that can leverage unlabeled data to produce pretrained models. While contrastive learning has demonstrated promising results on natural image classification tasks, its application to medical imaging tasks like chest X-ray interpretation has been limited. In this work, we propose MoCo-CXR, which is an adaptation of the contrastive learning method Momentum Contrast (MoCo), to produce models with better representations and initializations for the detection of pathologies in chest X-rays. In detecting pleural effusion, we find that linear models trained on MoCo-CXR-pretrained representations outperform those without MoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained representations are of higher-quality. End-to-end fine-tuning experiments reveal that a model initialized via MoCo-CXR-pretraining outperforms its non-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides the most benefit with limited labeled training data. Finally, we demonstrate similar results on a target Tuberculosis dataset unseen during pretraining, indicating that MoCo-CXR-pretraining endows models with representations and transferability that can be applied across chest X-ray datasets and tasks.')
}}
[% / %]
                        
{{ cloudflare_video('8d1f06d3ec92570032960f0fab4eb8cd') }}
                        

---
                        
[% .papers %]
{{ paper('Predicting molecular subtypes of breast cancer using multimodal deep learning and incorporation of the attention mechanism',
        'Tianyu Zhang, Luyi Han, Yuan Gao, Xin Wang, Regina Beets-Tan, Ritse Mann',
        openreview='https://openreview.net/forum?id=GHNGMR1EAtN',
        pdf='https://openreview.net/pdf?id=GHNGMR1EAtN',
        id='D4',
        paper='papers/D4.html',
        proceedings='',
        abstract='Accurately determining the molecular subtype of breast cancer is an important factor for the prognosis of breast cancer patients, and can guide treatment selection. In this study, we report a multimodal deep learning with attention mechanism (MDLA) for predicting the molecular subtypes of breast cancer from mammography and ultrasound images. Incorporation of the attention mechanism improved diagnostic performance for predicting 4-class molecular subtypes with Matthews correlation coefficient (MCC) of 0.794. The MDLA can also discriminate between Luminal disease and non-luminal disease with areas under the receiver operating characteristic curve (AUC) of 0.855. This work thus provides a noninvasive imaging biomarker to predict the molecular subtypes of breast cancer.')
}}
[% / %]
                        
{{ cloudflare_video('9ccffa963bff5d552c2d394f6ab1622f') }}
                        

---
                        
[% .papers %]
{{ paper('Double adversarial domain adaptation for whole-slide-imageclassification',
        'Yuchen Yang, Amir Akbarnejad, Nilanjan Ray, Gilbert Bigras',
        openreview='https://openreview.net/forum?id=70gFxx5ytwh',
        pdf='https://openreview.net/pdf?id=70gFxx5ytwh',
        id='D5',
        paper='papers/D5.html',
        proceedings='',
        abstract='Image classification on whole-slide-image (WSI) is a challenging task. A previous work based on Fisher vector encoding provided a novel end-to-end pipeline with promising accuracy and computational efficiency.However, this pipeline suffers from an accuracy drop when deployed to another dataset to perform the same task.This poses a limitation on the practical use of the pipeline especially when the diagnoses of WSIs are hard to obtain.This paper aims at providing a solution to mitigate the accuracy drop by using an unsupervised domain adaptation approach.We propose to insert the domain classifiers into the pipeline in two stages to align the features during training. We evaluate accuracy by calculating the confusion matrices before and after the adaptation on two datasets. We demonstrate that placing domain classifiers in different stages will boost accuracy.')
}}
[% / %]
                        
{{ cloudflare_video('07aa0cc4b07030f7692c9fdfc527818e') }}
                        

---
                        
[% .papers %]
{{ paper('Virtual Bone Shape Aging',
        'Francesco Caliva, Alejandro Morales Martinez, Sharmila Majumdar, Valentina Pedoia',
        openreview='https://openreview.net/forum?id=1JP1g5htY6K',
        pdf='https://openreview.net/pdf?id=1JP1g5htY6K',
        id='D6',
        paper='papers/D6.html',
        proceedings='',
        abstract='We use deep learning to age knee bone surfaces four years. We propose to encode an MRI-based bone surface in a spherical coordinate format, and use these spherical maps to predict shape changes in a 48 months time frame, in subjects with and without osteoarthritis. The experiments show that a 2D V-Net can predict bone surface shape with a mean absolute error of about 1 mm. Our code is available  at https://github.com/fcaliva/Bone_Shape_Virtual_Aging.')
}}
[% / %]
                        
{{ cloudflare_video('75e12b6e67a67b2a4eb2fea2d326188f') }}
                        

---
                        
[% .papers %]
{{ paper('Breast cancer patient stratification using domain adaptation based lymphocyte detection in HER2 stained tissue sections',
        'Ansh Kapil, Armin Meier, Anatoliy Shumilov, Susanne Haneder, Helen Angell, Günter Schmidt',
        openreview='https://openreview.net/forum?id=IAuBCvaTKHr',
        pdf='https://openreview.net/pdf?id=IAuBCvaTKHr',
        id='D7',
        paper='papers/D7.html',
        proceedings='',
        abstract='We extend the CycleGAN architecture with a style-based generator and show the efficacy of the proposed domain adaptation-based method between two histopathology image domains - Hematoxylin and Eosin (H&E) and HER2 immunohistochemically (IHC) images. Using the proposed method, we re-used large set of pre-existing annotations for detection of tumor infiltrating lymphocytes (TILs), which were originally done on H&E, towards a TIL detector applicable on HER2 IHC images. We provide analytical validation of the resulting TIL detector. Furthermore, we show that the detected stromal TIL densities are significantly prognostic as a biomarker for patient stratification on a triple-negative breast cancer (TNBC) cohort.')
}}
[% / %]
                        
{{ cloudflare_video('536c4ab6f20f9b213f38ec88973b18d2') }}
                        

---
                        
[% .papers %]
{{ paper('Cine-MRI detection of abdominal adhesions with spatio-temporal deep learning',
        'Bram de Wilde, Richard P. G. ten Broek, Henkjan Huisman',
        openreview='https://openreview.net/forum?id=-KI5qmKvhKQ',
        pdf='https://openreview.net/pdf?id=-KI5qmKvhKQ',
        id='D8',
        paper='papers/D8.html',
        proceedings='',
        abstract='Adhesions are an important cause of chronic pain following abdominal surgery. Recent developments in abdominal cine-MRI have enabled the non-invasive diagnosis of adhesions. Adhesions are identified on cine-MRI by the absence of sliding motion during movement. Diagnosis and mapping of adhesions  improves the management of patients with pain. Detection of abdominal adhesions on cine-MRI is challenging from both a radiological and deep learning perspective. We focus on classifying presence or absence of adhesions in sagittal abdominal cine-MRI series. We experimented with spatio-temporal deep learning architectures centered around a ConvGRU architecture. A hybrid architecture comprising a ResNet followed by a ConvGRU model allows to classify a whole time-series. Compared to a stand-alone ResNet with a two time-point (inspiration/expiration) input, we show an increase in classification performance (AUROC) from 0.74 to 0.83 (p<0.05). Our full temporal classification approach adds only a small amount (5%) of parameters to the entire architecture, which may be useful for other  medical imaging problems with a temporal dimension. ')
}}
[% / %]
                        
{{ cloudflare_video('cc47bccf82bba2f29eb434d997db1d85') }}
                        

---
                        
[% .papers %]
{{ paper('Efficient Video-Based Deep Learning for Ultrasound Guided Needle Insertion',
        'Jonathan Rubin, Alvin Chen, Anumod Odungattu Thodiyil, Raghavendra Srinivasa Naidu, Ramon Erkamp, Jon Fincke, Balasundar Raju',
        openreview='https://openreview.net/forum?id=dVUHL5QhDhL',
        pdf='https://openreview.net/pdf?id=dVUHL5QhDhL',
        id='D9',
        paper='papers/D9.html',
        proceedings='',
        abstract='We investigate video-based deep learning approaches for detecting needle insertions in ultrasound videos. We introduce two efficient and conceptually simple extensions to convert standard 2D object detectors into video object detectors that make use of temporal information from a history of frames. We compare our approaches to a 2D baseline method that makes independent predictions per frame. Given the need to run in real-time on computationally restricted environments, emphasis is placed on low computational complexity.')
}}
[% / %]
                        
{{ cloudflare_video('cdb30231447259480c93eb9dfb96ee32') }}
                        