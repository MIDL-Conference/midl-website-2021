---
title: "Session G1"
page_class: "program"
sidebar: false
---

{% from "_macros.html" import paper, cloudflare_video %}


# G1 - Interpretability and Explainable AI
##  Thursday 8th July, 16:45 - 17:30 (UTC+2)
### Chairs: Monika Grewal, Christian Ledig



---
                        
[% .papers %]
{{ paper('Me-NDT: Neural-backed Decision Tree for Visual Explainability of Deep Medical Models',
        'Guanghui FU, Ruiqian Wang, Jianqiang Li, Maria Vakalopoulou, Vicky Kalogeiton',
        openreview='https://openreview.net/forum?id=pL_aFZKNO5N',
        pdf='https://openreview.net/pdf?id=pL_aFZKNO5N',
        id='G1',
        paper='papers/G1.html',
        proceedings='',
        abstract='Despite the progress of deep learning on medical imaging, there is still not a true understanding of what networks learn and of how decisions are reached. Here, we address this by proposing a Visualized Neural-backed Decision Tree for Medical image analysis, Me-NDT. It is a CNN with a tree-based structure template that allows for both classification and visualization of firing neurons, thus offering interpretability. We also introduce node and path losses that allow Me-NDT to consider the entire path instead of isolated nodes. Our experiments on brain CT and chest radiographs outperform all baselines. Overall, Me-NDT is a lighter, comprehensively explanatory model, of great value for clinical practice. ')
}}
[% / %]
                        
{{ cloudflare_video('36cb22ef2608ea285f3e8393d6cfbff7') }}
                        

---
                        
[% .papers %]
{{ paper('ICAM-reg: Interpretable Classification and Regression with Feature Attribution for Mapping Neurological Phenotypes in Individual Scans',
        'Cher Bass, Mariana da Silva, Carole H. Sudre, Logan Zane John Williams, Petru-Daniel Tudosiu, Fidel Alfaro-Almagro, Sean P. Fitzgibbon, Matthew Glasser, Stephen M. Smith, Emma Claire Robinson',
        openreview='https://openreview.net/forum?id=164F3ixC9Jc',
        pdf='https://openreview.net/pdf?id=164F3ixC9Jc',
        id='G2',
        paper='papers/G2.html',
        proceedings='',
        abstract='Feature attribution (FA), or the assignment of class-relevance to different locations in an image, is important for many classification and regression problems but is particularly crucial within the neuroscience domain, where accurate mechanistic models of behaviours, or disease, require knowledge of all features discriminative of a trait. At the same time, predicting class relevance from brain images is challenging as phenotypes are typically heterogeneous, and changes occur against a background of significant natural variation.  Here, we present an extension of the ICAM framework for creating prediction specific FA maps through image-to-image translation.')
}}
[% / %]
                        
{{ cloudflare_video('7150f0537b05501fac962f565bbb758f') }}
                        

---
                        
[% .papers %]
{{ paper('Radiographic Assessment of CVC Malpositioning: How can AI best support clinicians?',
        'Lasse Hansen, Malte Sieren, Malte Hobe, Axel Saalbach, Heinrich Schulz, Jörg Barkhausen, Mattias P Heinrich',
        openreview='https://openreview.net/forum?id=ImcP8kkqtfZ',
        pdf='https://openreview.net/pdf?id=ImcP8kkqtfZ',
        id='G3',
        paper='papers/G3.html',
        proceedings='',
        abstract='The malpositioning of central venous catheters (CVCs) is a common technical complication that is usually diagnosed on post-procedure chest X-rays (CXRs). If the misplaced CVC remains undetected, it can lead to serious health consequences for the patient. Interpreting CXRs at a large scale in everyday clinical practice is time consuming and can create delays in the repositioning of the CVC. A computer-assisted assessment of post-procedure CXRs can help to prioritise cases and reduce human errors in stressful situations by objectifying decisions. However, final assessments must always be made by the clinicians, which is why the algorithmic support needs to be comprehensible.Since AI models are not yet able to detect catheter maplpositons with highest accuracy, the focus must be on efficient support in everyday clinical practice. In this work, we evaluate three different AI models, particularly with regard to the relationship between classification accuracy and the degree of explainability. Our results show how helpful it is to incorporate explicit clinical knowledge into deep learning-based models and give us promising research directions for a planned large scale patient study.')
}}
[% / %]
                        
{{ cloudflare_video('ad2f7ca85dca8c2ad61778a40fd3f522') }}
                        

---
                        
[% .papers %]
{{ paper('Test-Time Mixup Augmentation for Uncertainty Estimation in Skin Lesion Diagnosis',
        'Hansang Lee, Haeil Lee, Helen Hong, Junmo Kim',
        openreview='https://openreview.net/forum?id=aGfL5C9wRx_',
        pdf='https://openreview.net/pdf?id=aGfL5C9wRx_',
        id='G4',
        paper='papers/G4.html',
        proceedings='',
        abstract='Uncertainty is considered to be an important measure that provides valuable information on the learning behavior of deep neural networks. In this paper, we propose an uncertainty estimation method using test-time mixup augmentation (TTMA). The TTMA uncertainty is obtained by replacing affine augmentation with the mixup in the existing test-time augmentation (TTA) method. In addition to the data uncertainty, we propose TTMA-based class-specific uncertainty, which can provide information on between-class confusion. In experiments on the skin lesion diagnosis dataset, we confirmed that the proposed TTMA not only provides better epistemic uncertainty than TTA but also provides information on between-class confusion through class-specific uncertainty.')
}}
[% / %]
                        
{{ cloudflare_video('6bf1ea86b2a288925c58d81235a009f0') }}
                        

---
                        
[% .papers %]
{{ paper('Interpretable Medical Image Classification with Self-Supervised Anatomical Embedding and Prior Knowledge',
        'Ke Yan, Youbao Tang, Adam P Harrison, Jinzheng Cai, Le Lu, Jingjing Lu',
        openreview='https://openreview.net/forum?id=0wblcjbC2sN',
        pdf='https://openreview.net/pdf?id=0wblcjbC2sN',
        id='G5',
        paper='papers/G5.html',
        proceedings='',
        abstract='In medical image analysis tasks, it is important to make machine learning models focus on correct anatomical locations, so as to improve interpretability and robustness of the model. We adopt a latest algorithm called self-supervised anatomical embedding (SAM) to locate point of interest (POI) on computed tomography (CT) scans. SAM can detect arbitrary POI with only one labeled sample needed. Then, we can extract targeted features from the POIs to train a simple prediction model guided by clinical prior knowledge. This approach mimics the practice of human radiologists, thus is interpretable, controllable, and robust. We illustrate our approach on the application of CT contrast phase classification and it outperforms an existing deep learning based method trained on the whole image.')
}}
[% / %]
                        
{{ cloudflare_video('bedd476d3aecf72254a104e742dd6148') }}
                        

---
                        
[% .papers %]
{{ paper('50 shades of overfitting:  towards MRI-based neurologicalmodels interpretation',
        'Polina Druzhinina, Ekaterina Kondrateva, Evgeny Burnaev',
        openreview='https://openreview.net/forum?id=fnb58KJtYv',
        pdf='https://openreview.net/pdf?id=fnb58KJtYv',
        id='G6',
        paper='papers/G6.html',
        proceedings='',
        abstract="MRI-based prediction models are one of the most exploited AI solutions in neurology. Numerous computer-vision models showed their predictive ability for diverse psychoneurological conditions. Although most of these models are based on weak or no annotation, only a few reported studies interpret the predictions and perform the model saliency regions\\' analysis.We utilize 3DCNN interpretation with GradCAM to explore learned patterns for basic demographic characteristics prediction on the healthy cohort. We compare the saliency maps of the gender prediction models with the different types of MRI data preprocessing and augmentation. We assess the quality of learned patterns and examine the ways of models overfitting. We propose a data augmentation strategy based on optimal transport to avoid model overfitting on the brain volumes.")
}}
[% / %]
                        
{{ cloudflare_video('98b5bbef3f9e987a42e37478b24bee9e') }}
                        

---
                        
[% .papers %]
{{ paper('Weakly-supervised High-resolution Segmentation of Mammography Images for Breast Cancer Diagnosis',
        'Kangning Liu, Yiqiu Shen, Nan Wu, Jakub Piotr Chłędowski, Carlos Fernandez-Granda, Krzysztof J. Geras',
        openreview='https://openreview.net/forum?id=nBT8eNF7aXr',
        pdf='/proceedings/liu21b.pdf',
        id='G7',
        paper='papers/G7.html',
        proceedings='',
        abstract='In the last few years, deep learning classifiers have shown promising results in image-based medical diagnosis. However, interpreting the outputs of these models remains a challenge. In cancer diagnosis, interpretability can be achieved by localizing the region of the input image responsible for the output, i.e. the location of a lesion. Alternatively, segmentation or detection models can be trained with pixel-wise annotations indicating the locations of malignant lesions. Unfortunately, acquiring such labels is labor-intensive and requires medical expertise. To overcome this difficulty, weakly-supervised localization can be utilized. These methods allow neural network classifiers to output saliency maps highlighting the regions of the input most relevant to the classification task (e.g. malignant lesions in mammograms) using only image-level labels (e.g. whether the patient has cancer or not) during training. When applied to high-resolution images, existing methods produce low-resolution saliency maps. This is problematic in applications in which suspicious lesions are small in relation to the image size. In this work, we introduce a novel neural network architecture to perform weakly-supervised segmentation of high-resolution images. The proposed model selects regions of interest via coarse-level localization, and then performs fine-grained segmentation of those regions.We apply this model to breast cancer diagnosis with screening mammography, and validate it on a large clinically-realistic dataset. Measured by Dice similarity score, our approach outperforms existing methods by a large margin in terms of localization performance of benign and malignant lesions, relatively improving the performance by 39.6% and 20.0%, respectively. Code and the weights of some of the models are available at https://github.com/nyukat/GLAM')
}}
[% / %]
                        
{{ cloudflare_video('d4d41271a6bdc42b830a47f4f55a9380') }}
                        

---
                        
[% .papers %]
{{ paper('The OOD Blind Spot of Unsupervised Anomaly Detection',
        'Matthäus Heer, Janis Postels, Xiaoran Chen, Ender Konukoglu, Shadi Albarqouni',
        openreview='https://openreview.net/forum?id=ZDD2TbZn7X1',
        pdf='/proceedings/heer21.pdf',
        id='G8',
        paper='papers/G8.html',
        proceedings='',
        abstract='Deep unsupervised generative models are regarded as a promising alternative to supervised counterparts in the field of MRI-based lesion detection. They denote a principled approach for detecting unseen types of anomalies without relying on large amounts of expensive ground truth annotations. To this end, deep generative models are trained exclusively on data from healthy patients and detect lesions as  Out-of-Distribution (OOD) data at test time (i.e. low likelihood). While this is a promising way of bypassing the need for costly annotations, this work demonstrates that it also renders this widely used unsupervised anomaly detection approach particularly vulnerable to non-lesion-based OOD data (e.g. data from different sensors). Since models are likely to be exposed to such OOD data in production, it is crucial to employ safety mechanisms to filter for such samples and run inference only on input for which the model is able to provide reliable results. We first show extensively that conventional, unsupervised anomaly detection mechanisms fail when being presented with true OOD data. Secondly, we apply prior knowledge to disentangle lesion-based OOD from their non-lesion-based counterparts.')
}}
[% / %]
                        
{{ cloudflare_video('bb1bfdef26aeece6d0f0d0a63cee33c3') }}
                        

---
                        
[% .papers %]
{{ paper('A regularization term for slide correlation reduction in whole slide image analysis with deep learning',
        'Hongrun Zhang, Yanda Meng, Xuesheng Qian, Xiaoyun Yang, Sarah E Coupland, Yalin Zheng',
        openreview='https://openreview.net/forum?id=2vCFIoWDS6E',
        pdf='/proceedings/zhang21a.pdf',
        id='G9',
        paper='papers/G9.html',
        proceedings='',
        abstract='To develop deep learning-based models for automatic analysis of histopathology whole slide images (WSIs), the atomic entities to be directly processed are often the smaller patches cropped from WSIs as it is not always possible to feed a whole WSI to a model given its enormous size. However, a trained model tends to relate the slide-specific characteristics to diagnosis results because a large number of patches cropped from the same WSI will  share common slide features and thus have strong correlations between them, resulting in deteriorated generalization capability of the trained model. Current approaches to alleviate this issue include data pre-processing (stain normalization or color augmentation) and adversarial learning, both of which introduce extra complications in computations. Alternatively, we propose to reduce the impact of this issue by introducing a new regularization term to the standard loss function to reduce the correlation of the patches from the same WSI. It is intuitive and easy-to-implement and introduces comparably smaller  computation overhead compared to existing approaches. Experimental results prove that the proposed regularization term is able to enhance the generalization capability of learning models and consequently to achieve better performance. The code is available in:  \\url{https://github.com/hrzhang1123/SlideCorrelationReduction}.')
}}
[% / %]
                        
{{ cloudflare_video('6b61e01d2255a57e8bd1cbf2f05b7551') }}
                        