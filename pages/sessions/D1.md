---
title: "Session D1"
page_class: "program"
---

{% from "_macros.html" import button, paper, video %}

# D1 - Unsupervised and Representation Learning
##  Wednesday 7th July, 16:00 - 16:30 (UCT+2)
### Chairs: Jannis Hagenah, Caroline Petitjean



---
                        
[% .papers %]
{{ paper('Self-Rule to Adapt: Learning Generalized Features from Sparsely-Labeled Data Using Unsupervised Domain Adaptation for Colorectal Cancer Tissue Phenotyping',
        'Christian Abbet, Linda Studer, Andreas Fischer, Heather Dawson, Inti Zlobec, Behzad Bozorgtabar, Jean-Philippe Thiran',
        openreview='https://openreview.net/forum?id=VO7asaS5GUk',
        pdf='/proceedings/abbet21.pdf',
        id='D1',
        paper='papers/D1.html',
        proceedings='',
        abstract='Supervised learning is conditioned by the availability of labeled data, which are especially expensive to acquire in the field of medical image analysis. Making use of open-source data for pre-training or using domain adaptation can be a way to overcome this issue. However, pre-trained networks often fail to generalize to new test domains that are not distributed identically due to variations in tissue stainings, types, and textures. Additionally, current domain adaptation methods mainly rely on fully-labeled source datasets. In this work, we propose Self-Rule to Adapt (SRA) which takes advantage of self-supervised learning to perform domain adaptation and removes the burden of fully-labeled source datasets. SRA can effectively transfer the discriminative knowledge obtained from a few labeled source domain to a new target domain without requiring additional tissue annotations. Our method harnesses both domainsâ€™ structures by capturing visual similarity with intra-domain and cross-domain self-supervision. We show that our proposed method outperforms baselines across diverse domain adaptation settings and further validate our approach to our in-house clinical cohort.')
}}
[% / %]
                        
{{ video('/videos/full_16_video.mp4') }}
                        

---
                        
[% .papers %]
{{ paper('Semantic similarity metrics for learned image registration',
        'Steffen Czolbe, Oswin Krause, Aasa Feragen',
        openreview='https://openreview.net/forum?id=9M5cH--UdcC',
        pdf='/proceedings/czolbe21.pdf',
        id='D2',
        paper='papers/D2.html',
        proceedings='',
        abstract='We propose a semantic similarity metric for image registration. Existing metrics like euclidean distance or normalized cross-correlation focus on aligning intensity values, giving difficulties with low intensity contrast or noise. Our approach learns dataset-specific features that drive the optimization of a learning-based registration model. We train both an unsupervised approach using an auto-encoder, and a semi-supervised approach using supplemental segmentation data to extract semantic features for image registration. Comparing to existing methods across multiple image modalities and applications, we achieve consistently high registration accuracy. A learned invariance to noise gives smoother transformations on low-quality images.')
}}
[% / %]
                        
{{ video('/videos/full_28_video.mp4') }}
                        

---
                        
[% .papers %]
{{ paper('Nuc2Vec: Learning Representations of Nuclei in Histopathology Images with Contrastive Loss',
        'Chao Feng, Chad Vanderbilt, Thomas Fuchs',
        openreview='https://openreview.net/forum?id=uLtYvtWw8PH',
        pdf='/proceedings/feng21.pdf',
        id='D3',
        paper='papers/D3.html',
        proceedings='',
        abstract='The tumor microenvironment is an area of intense interest in cancer research and may be a clinically actionable aspect of cancer care. One way to study the tumor microenvironment is to characterize the spatial interactions between various types of nuclei in cancer tissue from H&E whole slide images, which require nucleus segmentation and classification. Current methods of nucleus classification rely on extensive labeling from pathologists and are limited by the number of categories a nucleus can be classified into. In this work, leveraging existing nucleus segmentation and contrastive representation learning methods, we developed a method that learns vector embeddings of nuclei based on their morphology in histopathology images. We show that the embeddings learned by this model capture distinctive morphological features of nuclei and can be used to group them into meaningful subtypes. These embeddings can provide a much richer characterization of the statistics of the spatial distribution of nuclei in cancer and open new possibilities in the quantitative study of the tumor microenvironment.')
}}
[% / %]
                        
{{ video('/videos/full_125_video.mp4') }}
                        