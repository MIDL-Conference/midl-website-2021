---
title: "Session A1"
page_class: "program"
sidebar: false
---

{% from "_macros.html" import paper, cloudflare_video %}


# A1 - Segmentation
##  Wednesday 7th July, 13:00 - 13:30 (UCT+2)
### Chairs: Minjeong Kim, Jelmer Wolterink



---
                        
[% .papers %]
{{ paper('Whole-Body Soft-Tissue Lesion Tracking and Segmentation in Longitudinal CT Imaging Studies',
        'Alessa Hering, Felix Peisen, Teresa Amaral, Sergios Gatidis, Thomas Eigentler, Ahmed Othman, Jan Hendrik Moltz',
        openreview='https://openreview.net/forum?id=hzbuHGhU02Z',
        pdf='/proceedings/hering21.pdf',
        id='A1',
        paper='papers/A1.html',
        proceedings='',
        abstract='In follow-up CT examinations of cancer patients, therapy success is evaluated by estimating the change in tumor size. This process is time-consuming and error-prone. We present a pipeline that automates the segmentation and measurement of matching lesions, given a point annotation in the baseline lesion. First, a region around the point annotation is extracted, in which a deep-learning-based segmentation of the lesion is performed. Afterward, a registration algorithm finds the corresponding image region in the follow-up scan and the convolutional neural network segments lesions inside this region. In the final step, the corresponding lesion is selected. We evaluate our pipeline on clinical follow-up data comprising 125 soft-tissue lesions from 43 patients with metastatic melanoma. Our pipeline succeeded for 96% of the baseline and 80% of the follow-up lesions, showing that we have laid the foundation for an efficient quantitative follow-up assessment in clinical routine.')
}}
[% / %]
                        
{{ cloudflare_video('2d0c1ea43a7ac5fbcec5405753fb26dc') }}
                        

---
                        
[% .papers %]
{{ paper('Embedding-based Instance Segmentation in Microscopy',
        'Manan Lalit, Pavel Tomancak, Florian Jug',
        openreview='https://openreview.net/forum?id=JM6GuFGayL5',
        pdf='/proceedings/lalit21.pdf',
        id='A2',
        paper='papers/A2.html',
        proceedings='',
        abstract='Automatic detection and segmentation of objects in 2D and 3D microscopy data is important for countless biomedical applications.In the natural image domain, spatial embedding-based instance segmentation methods are known to yield high-quality results, but their utility for segmenting microscopy data is currently little researched. Here we introduce EmbedSeg, an embedding-based instance segmentation method which outperforms existing state-of-the-art baselines on 2D as well as 3D microscopy datasets.Additionally, we show that EmbedSeg has a GPU memory footprint small enough to train even on laptop GPUs, making it accessible to virtually everyone. Finally, we introduce four new 3D microscopy datasets, which we make publicly available alongside ground truth training labels. Our open-source implementation is available at https://github.com/juglab/EmbedSeg.')
}}
[% / %]
                        
{{ cloudflare_video('83eca510fc92b56ac2ad18b55d973b59') }}
                        

---
                        
[% .papers %]
{{ paper('Beyond pixel-wise supervision: semantic segmentation with higher-order shape descriptors',
        'Hoel Kervadec, Houda Bahig, Laurent Letourneau-Guillon, Jose Dolz, Ismail Ben Ayed',
        openreview='https://openreview.net/forum?id=nqe6e0oJ_fL',
        pdf='/proceedings/kervadec21.pdf',
        id='A3',
        paper='papers/A3.html',
        proceedings='',
        abstract="Standard losses for training deep segmentation networks could be seen as individual classifications of pixels, instead of supervising the global shape of the predicted segmentations. While effective, they require exact knowledge of the label of each pixel in an image. This study investigates how effective global geometric shape descriptors could be, when used on their own as segmentation losses for training deep networks. Not only interesting theoretically, there exist deeper motivations to posing segmentation problems as a reconstruction of shape descriptors: First, annotations to obtain approximations of low-order shape moments could be much less cumbersome than their full-mask counterparts, and anatomical priors could be readily encoded into invariant shape descriptions, which might alleviate the annotation burden. Also, some shape descriptors could be readily used to encode\\'\\' biomarkers, leading to better interpretability. Finally, and most importantly, we hypothesize that, given a task, certain shape descriptions might be invariant across image acquisition protocols/modalities and subject populations, which might open interesting research avenues for generalization in medical image segmentation.We introduce and formulate a few shape descriptors in the context of deep segmentation, and evaluate their potential as stand-alone losses on two different, challenging tasks. Inspired by recent works in constrained optimization for deep networks, we propose a way to use those descriptors to supervise segmentation, without any pixel-level label. Very surprisingly, as little as 4 descriptors values per class can approach the performance of a segmentation mask with 65k individual discrete labels. We also found that shape descriptors can be a valid way to encode anatomical priors about the task, enabling to leverage expert knowledge without requiring additional annotations. Our implementation is publicly available and can be easily extended.")
}}
[% / %]
                        
{{ cloudflare_video('') }}
                        