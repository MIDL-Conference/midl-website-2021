---
title: "Session H4"
page_class: "program"
---

{% from "_macros.html" import paper, cloudflare_video %}


# H4 - Application
##  Thursday 8th July, 16:45 - 17:30 (UCT+2)
### Chairs: Raghav Mehta, Clarisa Sanchez



---
                        
[% .papers %]
{{ paper('A Surprisingly Effective Perimeter-based Loss for Medical Image Segmentation',
        'Rosana EL Jurdi, Caroline Petitjean, Paul Honeine, Veronika Cheplygina, Fahed Abdallah',
        openreview='https://openreview.net/forum?id=NDEmtyb4cXu',
        pdf='/proceedings/eljurdi21.pdf',
        id='H10',
        paper='papers/H10.html',
        proceedings='',
        abstract='Deep convolutional networks recently made many breakthroughs in medical image segmentation. Still, some anatomical artefacts may be observed in the segmentation results, with holes or inaccuracies near the object boundaries. To address these issues, loss functions that incorporate constraints, such as spatial information or prior knowledge, have been introduced. An example of such prior losses are the contour-based losses, which exploit distance maps to conduct point-by-point optimization between ground-truth and predicted contours. However, such losses may be computationally expensive or susceptible to trivial local solutions and vanishing gradient problems. Moreover, they depend on distance maps which tend to underestimate the contour-to-contour distances. We propose a novel loss constraint that optimizes the perimeter length of the segmented object relative to the ground-truth segmentation. The novelty lies in computing the perimeter with a soft approximation of the contour of the probability map via specialized non-trainable layers in the network. Moreover, we optimize the mean squared error between the predicted perimeter length and ground-truth perimeter length. This soft optimization of contour boundaries allows the network to take into consideration border irregularities within organs while still being efficient. Our experiments on three public datasets (spleen, hippocampus and cardiac structures) show that the proposed method outperforms state-of-the-art boundary losses for both single and multi-organ segmentation.')
}}
[% / %]
                        
{{ cloudflare_video('50712fdecebb56da9c8b960ca0ef6614') }}
                        

---
                        
[% .papers %]
{{ paper('Memory U-Net: Memorizing Where to Vote for Lesion Instance Segmentation',
        'Hang Zhang, Jinwei Zhang, Gufeng Yang, Pascal Spincemaille, Thanh D. Nguyen, Yi Wang',
        openreview='https://openreview.net/forum?id=JbWMYLN5Hba',
        pdf='/proceedings/zhang21b.pdf',
        id='H11',
        paper='papers/H11.html',
        proceedings='',
        abstract='Confluent lesions usually occur when pathologically distinct lesions grow close to each other and form a large spatially-connected lesion.   These confluent lesions pose a great challenge for subsequent image analysis and disease diagnosis, as individual lesions are difficult to separate and segment.In this paper, we propose a Memory U-Net that takes advantage of recent fully convolutional neural network U-Net and memory networks, to resolve the issue.The main idea is that we develop a hybrid model with a U-Net for feature extraction and a memory network as the alternative code book for generalized Hough voting.To alleviate the GPU memory overhead brought by the large code book, we decompose the large code book into three smaller ones, where each one of them accounts for voting in one specific direction.  Through voxel-wise voting, a density map of lesion locations can be obtained by aggregating votes from all lesion voxels, and this density map is further used to generate final instance segmentation results.Experiments on a large-scale cross-sectional multiple sclerosis study verify the efficiency and the effectiveness of the proposed method.')
}}
[% / %]
                        
{{ cloudflare_video('') }}
                        

---
                        
[% .papers %]
{{ paper('Unseen Disease Detection for Deep Learning Interpretation of Chest X-rays',
        'Siyu Shi, Ishaan Malhi, Kevin Tran, Andrew Y. Ng, Pranav Rajpurkar',
        openreview='https://openreview.net/forum?id=i-zxSlqneRu',
        pdf='/proceedings/shi21.pdf',
        id='H12',
        paper='papers/H12.html',
        proceedings='',
        abstract="We systematically evaluate the performance of deep learning models in the presence of diseases not labeled for or present during training. First, we evaluate whether deep learning models trained on a subset of diseases (seen diseases) can detect the presence of any one of a larger set of diseases. We find that models tend to falsely classify diseases outside of the subset (unseen diseases) as no disease\\'\\'. Second, we evaluate whether models trained on seen diseases can detect seen diseases when co-occurring with diseases outside the subset (unseen diseases). We find that models are still able to detect seen diseases even when co-occurring with unseen diseases. Third, we evaluate whether feature representations learned by models may be used to detect the presence of unseen diseases given a small labeled set of unseen diseases. We find that the penultimate layer provides useful features for unseen disease detection. Our results can inform the safe clinical deployment of deep learning models trained on a non-exhaustive set of disease classes.")
}}
[% / %]
                        
{{ cloudflare_video('e7448c1915c40f594e2483cfaac8b489') }}
                        

---
                        
[% .papers %]
{{ paper('Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting',
        'Brennan Nichyporuk, Justin Szeto, Douglas Arnold, Tal Arbel',
        openreview='https://openreview.net/forum?id=yVYVzsNWvN',
        pdf='https://openreview.net/pdf?id=yVYVzsNWvN',
        id='H4',
        paper='papers/H4.html',
        proceedings='',
        abstract='There are many clinical contexts which require accurate detection and segmentation of all focal pathologies (e.g. lesions, tumours) in patient images. In cases where there are a mix of small and large lesions, standard binary cross entropy loss will result in better segmentation of large lesions at the expense of missing small ones. Adjusting the operating point to accurately detect all lesions generally leads to oversegmentation of large lesions. In this work, we propose a novel reweighing strategy to eliminate this performance gap, increasing small pathology detection performance while maintaining segmentation accuracy. We show that our reweighing strategy vastly outperforms competing strategies based on experiments on a large scale, multi-scanner, multi-center dataset of Multiple Sclerosis patient images.')
}}
[% / %]
                        
{{ cloudflare_video('3f9c2f4f10b9fa9bf575a0534cdaae5f') }}
                        

---
                        
[% .papers %]
{{ paper('Creating Anthropomorphic Phantoms via Unsupervised Convolutional Neural Networks',
        'Junyu Chen, Ye Li, Yong Du, Eric Frey',
        openreview='https://openreview.net/forum?id=xqZTapYnEcG',
        pdf='https://openreview.net/pdf?id=xqZTapYnEcG',
        id='H5',
        paper='papers/H5.html',
        proceedings='',
        abstract='Computerized phantoms play an important role in medical imaging research. They can serve as a gold standard for evaluating and optimizing medical imaging analysis, processing, and reconstruction methods. Existing computerized phantoms model anatomical variations through organ and phantom scaling, which does not fully capture the range of anatomical variations seen in humans. Here, we present a registration-based method for creating highly realistic and detailed anthropomorphic phantoms. The proposed registration method is built on the use of an unsupervised convolutional neural network (ConvNet) that warps the four-dimensional Xtended Cardiac-Torso (XCAT) phantom to a patient CT scan. The registration ConvNet iteratively optimizes an SSIM-based loss function for a given image pair without prior training. We experimentally show substantially improved image similarity of the generated phantom using the proposed method to a patient image.')
}}
[% / %]
                        
{{ cloudflare_video('23ce21dd07b7992f4cc0369853365808') }}
                        

---
                        
[% .papers %]
{{ paper('Transformers for Ischemic Stroke Infarct Core Segmentation from Spatio-temporal CT Perfusion Scans',
        'Lucas de Vries, Bart Emmer, Charles Majoie, Henk Marquering, Efstratios Gavves',
        openreview='https://openreview.net/forum?id=CSNQMsxteqm',
        pdf='https://openreview.net/pdf?id=CSNQMsxteqm',
        id='H6',
        paper='papers/H6.html',
        proceedings='',
        abstract='The infarct core size is a crucial biomarker for treatment selection for ischemic stroke patients. For this purpose, we present a novel approach to perform infarct core segmentation using CT perfusion (CTP) source data, without ordinary deconvolution analysis. We propose the use of transformers to encode sequential CTP scans in spatial attention maps, which we subsequently use for infarct core segmentation. We report new top results on the ISLES 2018 challenge test data set for infarct core segmentation. This work presents a primary benchmark for infarct core segmentation from CTP source data using transformers.')
}}
[% / %]
                        
{{ cloudflare_video('2d574bd52987473706ca4d9f7fb95c55') }}
                        

---
                        
[% .papers %]
{{ paper('Multichannel input pixelwise regression 3D U-Nets for medical image estimation with 3 applications in brain MRI',
        'Jueqi Wang, Derek Berger, David Mattie, Jacob Levman',
        openreview='https://openreview.net/forum?id=JG895xlWsfA',
        pdf='https://openreview.net/pdf?id=JG895xlWsfA',
        id='H7',
        paper='papers/H7.html',
        proceedings='',
        abstract="The U-Net is a robust general-purpose deep learning architecture designed for semantic segmentation of medical images, and has been extended to 3D for volumetric applications such as magnetic resonance imaging (MRI) of the human brain. An adaptation of the U-Net to output pixelwise regression values, instead of class labels, based on multichannel input data, has been developed in the remote sensing satellite imaging research domain. The pixelwise regression U-Net has only received limited consideration as a deep learning architecture in medical imaging for the image estimation/synthesis problem, and the limited work so far did not consider the application of 3D multichannel inputs. In this paper, we propose the use of the multichannel input pixelwise regression 3D U-Net (rUNet) for estimation of medical images. Our findings demonstrate that this approach is robust and versatile and can be applied to predicting a pending MRI examination of patients with Alzheimer\\'s disease based on previous rounds of imaging, can perform medical image reconstruction (parametric mapping) in diffusion MRI, and can be applied to the estimation of one type of MRI examination from a collection of other types. Results demonstrate that the rUNet represents a single deep learning architecture capable of solving a variety of image estimation problems. Public domain code is provided.")
}}
[% / %]
                        
{{ cloudflare_video('f69f5ef9eb41a52814345e8346d61c18') }}
                        

---
                        
[% .papers %]
{{ paper('Morphology-based losses for weakly supervised segmentation of mammograms',
        'Mickael Tardy, Diana Mateus',
        openreview='https://openreview.net/forum?id=eehADvdlUa3',
        pdf='https://openreview.net/pdf?id=eehADvdlUa3',
        id='H8',
        paper='papers/H8.html',
        proceedings='',
        abstract='Segmentation is one of the most common tasks in medical imaging, but it often requires expensive ground truth for training. Weakly supervised methods cope with the lack of annotations, however, they often fall short compared to fully supervised ones. In this work, we propose to constrain the segmentation output with morphological operations, leading to an increase in the overall performance. In particular, we use top-hat and closing operations. We evaluate the method on high-resolution images from INBreast dataset and achieve an increase in F1 of approx. 0.14 and in recall of approx. 0.22 compared to the training without morphology loss.')
}}
[% / %]
                        
{{ cloudflare_video('a97270a33f089187725b8724c5593a00') }}
                        

---
                        
[% .papers %]
{{ paper('Partial Convolution Network for Metal Artifact Reduction in CT Preprocessing: Preliminary Results',
        'Laura Hellwege, Nele Blum, Thorsten Buzug, Maik Stille',
        openreview='https://openreview.net/forum?id=XCRthDLsCXn',
        pdf='https://openreview.net/pdf?id=XCRthDLsCXn',
        id='H9',
        paper='papers/H9.html',
        proceedings='',
        abstract='Metal artifacts impair the diagnostic value of medical CT images. These artifacts occur from the projection values associated with the metal objects inside the scanned anatomy. In this work, we replace the corrupted projection values by using a deep convolutional neural network consisting of so-called partial convolution layers. We show that the network trained on simulated data enhances newly presented projection data and therefore the corresponding reconstructed image. ')
}}
[% / %]
                        
{{ cloudflare_video('9006245765a0118cfc0801e14f4c8fc7') }}
                        